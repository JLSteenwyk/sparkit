# Configuration

Last updated: 2026-02-26

## Required environment variables
Set these provider keys in the runtime environment (do not hardcode):

- `ANTHROPIC_API_KEY`
- `OPENAI_API_KEY`
- `KIMI_API_KEY`
- `DEEPSEEK_API_KEY`
- `GROK_API_KEY`
- `MISTRAL_API_KEY`
- `GEMINI_API_KEY` or `GOOGLE_API_KEY`
- `BRAVE_SEARCH_API_KEY` (optional; only for Google-like web discovery when enabled)
- `EXA_API_KEY` (optional; enables Exa search/answer/content/research adapters when enabled)
- `PUBMED_API_KEY` (optional; increases NCBI E-utilities rate limit for PubMed metadata adapter)
- `PUBMED_EMAIL` (optional but recommended by NCBI for E-utilities identification)
- `PUBMED_TOOL` (optional; default `sparkit`)

## Database
- `DATABASE_URL` (example: `postgresql://postgres:postgres@localhost:5432/sparkit`)
  - also used by local corpus tables: `corpus_documents`, `corpus_chunks`

## Optional provider overrides
- `KIMI_BASE_URL` (default: `https://api.moonshot.ai`)
- `KIMI_TEMPERATURE` (default: `1.0`)
- `OPENAI_MODEL` (default: `gpt-5.2`)
- `OPENAI_REASONING_EFFORT` (optional; `low|medium|high|xhigh`, applied for GPT-5 models via Responses API)
- `ANTHROPIC_MODEL` (default: `claude-opus-4-6`)
- `ANTHROPIC_THINKING_ENABLED` (default: `0`; set `1` to enable Claude thinking mode)
- `ANTHROPIC_THINKING_BUDGET_TOKENS` (default: `3000`; effective only when thinking is enabled and token budget allows)
- `KIMI_MODEL` (default: `kimi-k2-turbo-preview`)
- `GEMINI_MODEL` (default: `gemini-3-pro-preview`)
  - Also supported in exact pricing: `gemini-3.1-pro-preview`
- `GEMINI_THINKING_BUDGET_TOKENS` (default: `0`; set >0 to enable Gemini `generationConfig.thinkingConfig.thinkingBudget`)
- `DEEPSEEK_MODEL` (default: `deepseek-reasoner`)
- `GROK_MODEL` (default: `grok-4-0709`)
  - Also supported in exact pricing: `grok-4-fast-reasoning`, `grok-4-fast-non-reasoning`
- `MISTRAL_MODEL` (default: `mistral-large-2512`)
- `DEEPSEEK_BASE_URL` (default: `https://api.deepseek.com`)
- `GROK_BASE_URL` (default: `https://api.x.ai`)
- `MISTRAL_BASE_URL` (default: `https://api.mistral.ai`)
- `SPARKIT_PROVIDER_TIMEOUT_S` (default: `35`)
- `<PROVIDER>_TIMEOUT_S` per-provider override (examples: `GROK_TIMEOUT_S`, `DEEPSEEK_TIMEOUT_S`)
- `SPARKIT_INGESTION_MAX_CHARS` (default: `10000`, chars parsed per ingested document)
- `SPARKIT_RETRIEVAL_EXTRA_RESULTS` (default: `8`, added to requested `min_sources` in standard mode)
- `SPARKIT_RETRIEVAL_MIN_RESULTS_FLOOR` (default: `14`, minimum per-query retrieval target in standard mode)
- `SPARKIT_INGESTION_EXTRA_DOCS` (default: `6`, added to requested `min_sources` for ingestion target in standard mode)
- `SPARKIT_INGESTION_TARGET_DOCS_FLOOR` (default: `10`, minimum ingested-doc target in standard mode)
- `SPARKIT_RETRIEVAL_EXTRA_RESULTS_RESEARCH_MAX` (default: `12`)
- `SPARKIT_RETRIEVAL_MIN_RESULTS_FLOOR_RESEARCH_MAX` (default: `18`)
- `SPARKIT_INGESTION_EXTRA_DOCS_RESEARCH_MAX` (default: `8`)
- `SPARKIT_INGESTION_TARGET_DOCS_FLOOR_RESEARCH_MAX` (default: `14`)
- `DIRECT_CALL_MAX_ATTEMPTS` (default: `3`, applies to direct single-call baselines)
- `DIRECT_CALL_RETRY_BACKOFF_S` (default: `0.8`, exponential backoff base seconds)
- `SPARKIT_MODEL_PRICING_JSON` (optional per-model pricing override map)
- `SPARKIT_ENABLE_WEB_SEARCH` (default: `0`; set `1` to enable Brave web-search adapter in retrieval)
- `SPARKIT_SCIENCE_ENHANCED_MODE` (default: `1`; enforces academic-domain filtering for web-style evidence sources such as Brave/Exa unless DOI-backed)
- `SPARKIT_ENABLE_EXA_SEARCH` (default: `0`; set `1` to enable Exa search adapter in retrieval)
- `SPARKIT_ENABLE_PUBMED_METADATA` (default: `0`; set `1` to enable PubMed E-utilities metadata adapter in live retrieval)
- `SPARKIT_ENABLE_EXA_ANSWER` (default: `0`; set `1` to enable Exa answer adapter in retrieval)
- `SPARKIT_ENABLE_EXA_RESEARCH` (default: `0`; set `1` to enable Exa research adapter in retrieval)
- `SPARKIT_ENABLE_EXA_CONTENT` (default: `0`; set `1` to enrich retrieved URLs with Exa content API)
- `SPARKIT_EXA_CONTENT_MAX_URLS` (default: `12`; max URLs to hydrate via Exa content endpoint per retrieval call)
- `EXA_RESEARCH_MODEL` (default: `exa-research`; Exa research model override)
- `SPARKIT_EXA_RESEARCH_POLL_TIMEOUT_S` (default: `90`; polling timeout for Exa research jobs)
- `SPARKIT_EXA_RESEARCH_POLL_INTERVAL_S` (default: `2`; poll interval seconds for Exa research jobs)
- `SPARKIT_ENABLE_LIVE_RETRIEVAL` (default: `1`; set `0` to disable live network adapters and use local corpus retrieval only)
- `SPARKIT_ENABLE_FALSIFICATION_ROUND` (default: `1`; adds a dedicated falsification retrieval round)
- `SPARKIT_FALSIFICATION_MAX_QUERIES` (default: `10`; cap for generated falsification queries)
- `SPARKIT_FALSIFICATION_MAX_OPTIONS` (default: `2`; MCQ falsification focuses on top candidate options)
- `SPARKIT_ENABLE_SEMANTIC_RERANK` (default: `0`; enables stage-targeted LLM semantic reranking for retrieval rounds)
- `SPARKIT_SEMANTIC_RERANK_STAGES` (default: `retrieval_round_2_gap_fill,retrieval_round_3_adversarial,retrieval_round_4_falsification`)
- `SPARKIT_ENABLE_SEMANTIC_RERANK_FINAL` (default: inherits `SPARKIT_ENABLE_SEMANTIC_RERANK`; reranks final ingestion set before parsing)
- `SPARKIT_SEMANTIC_RERANK_CANDIDATES` (default: `18`; candidate cap for semantic rerank prompt)
- `SPARKIT_INGESTION_DIVERSITY_LAMBDA` (default: `0.75`; MMR-style relevance/novelty tradeoff for ingestion selection)
- `SPARKIT_SOURCE_QUALITY_WEIGHT` (default: `1.10`; how strongly source-quality contributes to ingestion ranking vs lexical relevance)
- `SPARKIT_HQ_SOURCE_THRESHOLD` (default: `1.70`; threshold for classifying a record as high-quality in consensus gating)
- `SPARKIT_ENABLE_MCQ_EVIDENCE_GATE` (default: `1`; requires selected MCQ option to have sufficient option-level support evidence)
- `SPARKIT_MCQ_EVIDENCE_MIN_SUPPORT_SNIPPETS` (default: `2`)
- `SPARKIT_MCQ_EVIDENCE_MIN_DOSSIER_SCORE` (default: `1.8`)
- `SPARKIT_MCQ_EVIDENCE_MIN_NET_SCORE` (default: `0.0`)
- `SPARKIT_MCQ_EVIDENCE_GATE_CONF_PENALTY` (default: `0.20`; confidence penalty if gate fails at finalization)
- `SPARKIT_ENABLE_MCQ_DUAL_SCORER` (default: `1`; runs a second adversarial MCQ scorer pass and blends both score sets)
- `SPARKIT_ENABLE_MCQ_ARBITRATION_FALLBACK` (default: `1`; when MCQ scorer/judge output is unparseable, run a strict arbitration call instead of heuristic defaulting)
- `SPARKIT_ENABLE_MCQ_STRICT_ELIGIBILITY` (default: `1`; only options meeting support/dossier/net/blended thresholds are eligible for selection)
- `SPARKIT_MCQ_ELIGIBILITY_MIN_SUPPORT_SNIPPETS` (default: `2`)
- `SPARKIT_MCQ_ELIGIBILITY_MIN_DOSSIER_SCORE` (default: `1.8`)
- `SPARKIT_MCQ_ELIGIBILITY_MIN_NET_SCORE` (default: `0.0`)
- `SPARKIT_MCQ_ELIGIBILITY_MIN_BLENDED_SCORE` (default: `0.0`)
- `SPARKIT_MCQ_HARD_BLOCK_ON_WEAK_EVIDENCE` (default: `1`; if final MCQ evidence gate fails, emit `<answer>UNKNOWN</answer>` instead of forcing a low-evidence letter)
- `SPARKIT_MCQ_COVERAGE_MAX_ATTEMPTS` (default: `2`; pre-synthesis retrieval expansion rounds to satisfy option coverage)
- `SPARKIT_MCQ_COVERAGE_MIN_SUPPORT_CLAIMS` (default: `1`; minimum structured support claims required per MCQ option)
- `SPARKIT_MCQ_COVERAGE_MIN_SUPPORT_SOURCES` (default: `1`; minimum independent supporting sources required per MCQ option)
- `SPARKIT_MCQ_COVERAGE_MAX_OPTIONS` (default: `8`; max option labels enforced by coverage gate on very large-choice MCQs)
- `SPARKIT_MCQ_COVERAGE_MAX_QUERIES` (default: `18`; cap for option-targeted expansion queries per attempt)
- `SPARKIT_OPTION_GRAPH_V2_MAX_OPTIONS` (default: `10`; number of options to explicitly include in option-contrast retrieval rounds for `option_graph_v2`)
- `SPARKIT_SIMPLE_RAG_TOP_CHUNKS` (default: `3`; number of top semantic chunks used for extractive evidence summaries per ingested document in `simple_rag`)
- MCQ option prompts now use deterministic label permutation + explicit anti-letter-prior guidance to reduce A/B positional bias.
- `SPARKIT_ENABLE_CLAIM_GAP_LOOP` (default: `1`; injects claim-gap follow-up queries from each completed retrieval round into the next round)
- `SPARKIT_CLAIM_GAP_MAX_QUERIES` (default: `4`; max injected claim-gap queries per stage)
- `SPARKIT_CLAIM_GAP_MAX_NEXT_QUERIES` (default: `12`; max merged query count for next stage after gap injection)
- `SPARKIT_CLAIM_GAP_REQUIRE_LOW_EVIDENCE` (default: `1`; only inject gaps when stage evidence appears weak)
- `SPARKIT_CLAIM_GAP_MIN_NEW_DOCS_TRIGGER` (default: `2`; low-novelty threshold for claim-gap injection)
- `SPARKIT_CLAIM_GAP_MIN_RELEVANCE_TRIGGER` (default: `1.2`; low-relevance threshold for claim-gap injection)
- `SPARKIT_CLAIM_GAP_MAX_COST_RATIO` (default: `0.7`; skip claim-gap injection when spent/max_cost exceeds ratio)
- `SPARKIT_CLAIM_GAP_MAX_LATENCY_RATIO` (default: `0.7`; skip claim-gap injection when elapsed/max_latency exceeds ratio)
- `SPARKIT_CLAIM_GAP_FORCE` (default: `0`; force claim-gap injection regardless of evidence/headroom guards)

## Benchmark model presets
- `single_openai`: provider `openai` using current `OPENAI_MODEL` (default `gpt-5.2`)
- `single_openai_pro`: provider `openai` with override `OPENAI_MODEL=gpt-5.2-pro`
- `single_anthropic`: provider `anthropic` using current `ANTHROPIC_MODEL` (default `claude-opus-4-6`)
- `single_anthropic_sonnet`: provider `anthropic` with override `ANTHROPIC_MODEL=claude-sonnet-4-6`
- `single_gemini`: provider `gemini` using current `GEMINI_MODEL` (default `gemini-3-pro-preview`)
- `single_kimi`: provider `kimi` using current `KIMI_MODEL` (default `kimi-k2-turbo-preview`)
- `single_deepseek`: provider `deepseek` using current `DEEPSEEK_MODEL` (default `deepseek-reasoner`)
- `single_grok`: provider `grok` using current `GROK_MODEL` (default `grok-4-0709`)
- `single_mistral`: provider `mistral` using current `MISTRAL_MODEL` (default `mistral-large-2512`)
- `routed_frontier_plus`: routed config over OpenAI + Anthropic + Gemini + DeepSeek + Grok + Mistral + Kimi

## Runtime tuning knobs (per request)
- `constraints.synthesis_max_tokens` overrides synthesis token budget per run.
- Current mode defaults when unset:
  - `single_*` / `routed`: synthesis max tokens is uncapped (`null`), retrieval minimum `max(min_sources+8,14)`, ingestion target docs `max(min_sources+6,10)`
  - `simple_rag`: synthesis max tokens uncapped (`null`), retrieval rounds are simplified to primary + support, and ingestion uses semantic chunk matching + extractive summaries
  - `option_graph_v2`: synthesis max tokens uncapped (`null`), with additional option-support/option-contrast retrieval rounds before standard gap-fill/adversarial rounds
  - `research_max`: synthesis max tokens uncapped (`null`), retrieval minimum `max(min_sources+12,18)`, ingestion target docs `max(min_sources+8,14)`
  - `ensemble`: synthesis max tokens uncapped (`null`) per draft
- Adaptive retrieval continuation:
  - `SPARKIT_ADAPTIVE_RETRIEVAL` (default: `1`)
  - `SPARKIT_ADAPTIVE_MIN_ROUNDS` (default: `2`)
  - `SPARKIT_ADAPTIVE_MAX_ROUNDS` (default: planned round count)
  - `SPARKIT_ADAPTIVE_MIN_NEW_DOCS` (default: `2`)
  - `SPARKIT_ADAPTIVE_MIN_QUALITY_GAIN` (default: `0.03`)
  - Behavior: retrieval stops early when rounds stop adding novel/high-relevance evidence, with decision trace in `retrieval_adaptive_gate`.
- Answerability gate behavior:
  - `SPARKIT_DISABLE_HARD_ABSTAIN` (default: `0`)
  - When set to `1`, SPARKIT keeps the best synthesized answer text (soft-abstain) instead of replacing it with an "insufficient evidence" refusal, while still lowering confidence and recording abstain reasons.

## Notes
- Retrieval source coverage includes: arXiv, Crossref, Semantic Scholar, OpenAlex, Europe PMC, and optional Exa adapters (`search`, `answer`, `research`, `content` hydration).
- Finalization now applies an evidence-consensus gate: confidence is penalized when decisive claims lack independent high-quality source support.
- Retrieval science mode defaults to academic-first filtering for web-style sources (`brave_web`, `exa_web`, `exa_answer`, `exa_research`, `exa_content`), reducing non-scholarly evidence leakage.
- Optional Google-like discovery: Brave Search adapter (key-gated + science-domain filtering) when `SPARKIT_ENABLE_WEB_SEARCH=1`.
- Retrieval uses local-first corpus lookup when populated, then falls back to live source federation.
- Evidence ingestion/retrieval hard-blocks HLE-related domains (`huggingface.co`, `futurehouse.org`) to prevent benchmark-answer leakage through downloaded content.
- `GEMINI_API_KEY` and `GOOGLE_API_KEY` are treated as alternatives for Google models.
- Gemini thinking config note: `thinkingConfig` must be nested under `generationConfig`.
- Anthropic thinking note: SPARKIT omits `temperature` when thinking mode is enabled for Messages API compatibility.
- Keep keys in environment/secrets manager only.
- Default exact pricing map (per 1M tokens):
  - `gpt-5.2`: input cache hit `$0.175`, input cache miss `$1.75`, output `$14.00`
  - `gpt-5.2-pro`: input cache hit `$21.00`, input cache miss `$21.00`, output `$168.00`
  - `claude-opus-4-6`: input cache hit `$0.50`, input cache miss `$5.00`, output `$25.00`
  - `claude-sonnet-4-6`: input cache hit `$0.30`, input cache miss `$3.00`, output `$15.00`
  - `gemini-3-pro-preview`: input cache hit `$0.20`, input cache miss `$2.00`, output `$12.00` (prompt >200k tokens tier: `$0.40`, `$4.00`, `$18.00`)
  - `gemini-3.1-pro-preview`: input cache hit `$0.20`, input cache miss `$2.00`, output `$12.00` (prompt >200k tokens tier: `$0.40`, `$4.00`, `$18.00`)
  - `kimi-k2-turbo-preview`: input cache hit `$0.10`, input cache miss `$0.60`, output `$3.00`
  - `deepseek-reasoner`: input cache hit `$0.028`, input cache miss `$0.28`, output `$0.42`
  - `grok-4-0709`: input cache hit `$0.75`, input cache miss `$3.00`, output `$15.00`
  - `grok-4-fast-reasoning`: input cache hit `$0.20`, input cache miss `$0.20`, output `$0.50`
  - `grok-4-fast-non-reasoning`: input cache hit `$0.20`, input cache miss `$0.20`, output `$0.50`
  - `mistral-large-2512`: input cache hit `$2.00`, input cache miss `$2.00`, output `$6.00`
- Brave Search request pricing (for retrieval web adapter):
  - `$5.00 / 1,000 requests` = `$0.005` per request
  - SPARKIT now tracks actual Brave request attempts during retrieval and adds this to run `provider_usage` as `provider=brave_web`, `model=search-api`.
- Exa request pricing (for retrieval adapters):
  - Search (1-25 results): `$5.00 / 1,000` requests (`exa_web`).
  - Search (26-100 results): `$25.00 / 1,000` requests (not used by default, current `numResults <= 25`).
  - Content: `$1.00 / 1,000` pieces (`exa_content`, tracked via `exa_content_pieces`).
  - Answer: `$5.00 / 1,000` requests (`exa_answer`).
  - Research: `$5.00 / 1,000` agent searches (`exa_research`).
  - Research page reads / reasoning tokens are supported in policy function, but current retrieval telemetry does not yet emit those counters by default.
- Cost precision note: exact generation cost is computed when model pricing is configured (built-in defaults + `SPARKIT_MODEL_PRICING_JSON` overrides). Unknown models fall back to deterministic synthesis-stage estimates.
- `SPARKIT_MODEL_PRICING_JSON` supports either:
  - `{"provider:model":{"input_cache_hit":...,"input_cache_miss":...,"output":...}}`
  - `{"provider":{"model":{"input_cache_hit":...,"input_cache_miss":...,"output":...}}}`
- Latency policy note: default `max_latency_s` is unset (`null`), so no latency cap is applied unless explicitly set.
- Direct-call quality note: empty parsed answers are now counted as failures (`empty_answer_text`).
- Benchmark manifest includes MCQ collapse detection fields per config (`mcq_letter_distribution`, `mcq_dominant_ratio`, `mcq_collapse_warning`), with threshold controlled by `SPARKIT_MCQ_COLLAPSE_THRESHOLD` (default `0.70`).
- Per-question benchmark predictions now include `mcq_decision` provenance (selected-via scorer/judge/fallback/rescue/hard-block, gate pass/fail, parse-failure sources).
- PaperQA-inspired retrieval controls:
  - `SPARKIT_ENABLE_RCS_RERANK` (default: `1`; question-conditioned relevance scoring over candidates before optional semantic rerank)
  - `SPARKIT_RCS_RERANK_CANDIDATES` (default: `20`)
  - `SPARKIT_ENABLE_CITATION_TRAVERSAL_QUERIES` (default: `1`; inject citation/follow-up queries from retrieved papers into the next round)
  - `SPARKIT_CITATION_TRAVERSAL_MAX_QUERIES` (default: `4`)
  - `SPARKIT_CITATION_TRAVERSAL_MAX_NEXT_QUERIES` (default: `14`)
- DeepSeek direct-call note: when DeepSeek returns empty `message.content` but populated `reasoning_content`, provider adapter falls back to reasoning text to avoid false hard-failures.
- Timeout note: tuned provider defaults are Grok `60s`, DeepSeek `45s`, and `35s` for other providers unless overridden by env vars.
- Kimi response note: Kimi responses with empty `message.content` are treated as failures to avoid silently accepting reasoning-only outputs.
- Baseline capture command: `make baseline-capture` (writes outputs to `benchmarks/results/`).
- Official baseline capture command: `make baseline-capture-official`.
- Benchmark generation command: `make benchmark-generate`.
- HLE bio/chem subset generation: `make benchmark-generate-hle-biochem-20`.
- HLE bio/chem subset baseline capture: `make baseline-capture-hle-biochem-20`.
- HLE bio/chem direct-call baselines (single raw API call per question): `make baseline-capture-direct-calls-hle20`.
- Repeated-slice benchmark with CI: `make benchmark-repeated-slices`.
- Full benchmark eval command: `make eval-benchmark-full`.
- Drift check command (sample): `make drift-check-sample`.
- Corpus build command (broad science ingestion): `make corpus-build`.
- Scholarly metadata ingestion command (metadata-first + targeted fulltext for top candidates): `./venv/bin/python scripts_ingest_scholarly_metadata.py --questions benchmarks/hle_gold_bio_chem/questions_barometer10_direct30.json --include-pubmed --fulltext-top-k 6`.
