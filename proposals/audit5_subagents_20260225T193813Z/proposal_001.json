```json
{"proposal_id":"audit5-retrieval-sed-001","title":"Stepwise Epistemic Decomposition with Marginal-Coverage Reranking","distinctive_angle":"Sequential, context-conditioned query decomposition where each sub-query is informed by what prior retrieval steps already established — eliminating redundant retrieval and targeting only the residual knowledge gap at each stage, with reranking scored on marginal information gain rather than relevance-to-query.","summary":"Hard STEM questions typically require establishing a chain of intermediate facts before the final answer can be derived. Current parallel decomposition retrieves sub-queries independently, causing (a) redundant passages that crowd out genuinely novel evidence, and (b) poor coverage of late-chain facts that depend on early-chain context. SED decomposes questions into an ordered epistemic dependency graph, retrieves sequentially so each step's query is conditioned on prior retrieved context, and reranks candidates at each step by marginal coverage — the fraction of unresolved claim-slots they fill beyond what is already in the running context window.","reasoning":"On hard STEM questions (chemistry mechanisms, multi-step physics derivations, genomics pathway questions), the information needed is typically compositional: Fact B is only retrievable with the right terminology once Fact A is known. A query for 'inhibition of CYP3A4 by macrolide antibiotics causing QT prolongation' is too broad; but after retrieving a passage establishing CYP3A4's role in pimozide metabolism, the follow-up query 'pimozide plasma concentration cardiac arrhythmia threshold' becomes precise and high-recall. Parallel decomposition misses this because sub-queries are generated before any retrieval context exists. Marginal-coverage reranking then ensures that the top-k passages fed to the reasoning model collectively span all claim-slots rather than converging on a single well-matched but informationally redundant cluster. This directly addresses the three audit lens areas: coverage (sequential retrieval finds late-chain facts), query decomposition (dependency graph ordering), and reranking (marginal gain objective).","expected_impact":{"accuracy_delta_pct_points":7,"cost_impact":"increase","latency_impact":"increase","confidence":"medium"},"implementation_plan":[{"step":"Add an EpistemicDecomposer module that calls the LLM once to emit an ordered list of (claim_slot, depends_on) tuples from the question, forming a DAG of prerequisite facts.","owner":"retrieval-team","effort":"medium"},{"step":"Implement sequential retrieval loop: for each claim_slot in topological order, construct the sub-query by appending a 'given: {prior_context_summary}' prefix so the embedding captures late-chain specificity.","owner":"retrieval-team","effort":"medium"},{"step":"Replace cosine-similarity reranking with Marginal Coverage Reranker: score each candidate passage by |new_claim_slots_covered| / |total_unresolved_claim_slots|, using a lightweight NLI model to check coverage.","owner":"reranking-team","effort":"high"},{"step":"Add a coverage-completion gate: halt retrieval when all claim_slots reach coverage >= 0.85 or max_steps is reached, preventing over-retrieval on easy questions.","owner":"retrieval-team","effort":"low"},{"step":"Evaluate on HLE biology/chemistry subset and the existing barometer benchmark; compare total tokens retrieved, redundancy ratio (cosine similarity among top-k passages), and final accuracy.","owner":"eval-team","effort":"medium"}],"retrieval_improvements":["Sequential context-conditioned sub-queries improve recall of late-chain terminology-specific facts that parallel decomposition systematically misses","Marginal Coverage Reranker eliminates passage-cluster redundancy, fitting more distinct evidence into the fixed top-k context window","Coverage-completion gate reduces over-retrieval on simple sub-questions, keeping token budget for genuinely hard claim-slots"],"evaluation_plan":["Run on HLE-25 balanced subset (existing benchmark) and report accuracy delta vs current claim-gap baseline, segmented by STEM domain (bio/chem/physics/math)","Measure retrieval quality intrinsically: for a held-out set with annotated claim-slots, report claim-slot recall@k before and after, and inter-passage redundancy (mean pairwise cosine similarity of top-6 passages)","Ablation study: sequential-only (no marginal reranking) vs marginal-reranking-only (parallel decomp) vs full SED, to isolate contribution of each component"],"risks":["Sequential retrieval increases latency linearly with DAG depth; mitigation: parallelize independent sibling nodes in the DAG rather than forcing fully sequential execution","EpistemicDecomposer adds one LLM call per question; if decomposition quality is poor (e.g. wrong dependency ordering), downstream retrieval degrades — needs fallback to parallel decomp when DAG confidence is low","NLI-based coverage scoring is approximate; a weak NLI model may incorrectly mark claim-slots as covered, causing premature gate termination — validate NLI calibration on STEM-specific entailment pairs before deployment"]}
```
