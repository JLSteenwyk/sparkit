```json
{"proposal_id":"audit5-orch-savl-001","title":"Staged Adversarial Verification Loop (SAVL): Falsification-First Critic Orchestration","distinctive_angle":"Treat falsification as a first-class orchestration primitive rather than a post-hoc review step. A dedicated Critic agent is tasked with disproving each intermediate claim before the Orchestrator accepts it, forcing targeted re-retrieval and re-planning on any disputed node rather than only at the final answer boundary.","summary":"Replace the current single-pass planner→answer→critic flow with a structured multi-stage loop: (1) Planner decomposes the hard STEM question into an explicit DAG of intermediate claims with stated assumptions; (2) Critic agents independently attempt to falsify each node via adversarial retrieval and symbolic checking; (3) Verifier runs dimensional/unit/order-of-magnitude consistency checks on numerical results; (4) Orchestrator routes failed nodes back to the Planner with failure reasons as injected constraints, capping total iterations. Only answers where all nodes survive falsification and pass Verifier are emitted with high confidence.","reasoning":"Hard STEM failures in SPARKIT cluster around two failure modes: (a) plausible-but-wrong intermediate steps that propagate undetected to the final answer, and (b) retrieval gaps where the system hallucinates domain facts instead of fetching them. A falsification-first critic loop directly attacks both: adversarial retrieval on each intermediate claim surfaces gaps before they compound, and the symbolic Verifier catches unit/magnitude errors that language models systematically miss. This tightens the feedback loop from 'answer-level correction' to 'claim-level correction', dramatically reducing error propagation in multi-step STEM reasoning chains. The DAG decomposition also enables parallel critic execution across independent sub-claims, partially offsetting latency cost.","expected_impact":{"accuracy_delta_pct_points":8,"cost_impact":"increase","latency_impact":"increase","confidence":"medium"},"implementation_plan":[{"step":"Define ClaimDAG schema: each node has claim_text, dependencies[], assumptions[], evidence_refs[], status (unverified|verified|falsified)","owner":"orchestrator-core","effort":"medium"},{"step":"Implement Planner v2 prompt that outputs a ClaimDAG JSON instead of a flat reasoning chain; include explicit assumption listing per node","owner":"planner-module","effort":"medium"},{"step":"Build Critic agent: given a ClaimDAG node, construct a falsification query (negation of claim + retrieval), return (verdict, evidence, rebuttal_hint)","owner":"critic-module","effort":"high"},{"step":"Build Verifier agent: for nodes containing numerical results, run dimensional analysis, order-of-magnitude sanity check, and cross-reference against known constants; flag if result deviates by >1 OOM from expectation","owner":"verifier-module","effort":"high"},{"step":"Implement Orchestrator loop: fan-out Critic calls across independent DAG nodes in parallel; on falsification, inject rebuttal_hint into Planner context and re-plan only the affected sub-DAG; cap at 3 re-plan iterations per node","owner":"orchestrator-core","effort":"high"},{"step":"Add confidence scoring: final answer confidence = f(fraction of nodes verified, number of re-plan iterations consumed, Verifier deviation score)","owner":"scoring-module","effort":"low"},{"step":"Benchmark on HLE hard STEM subset (bio/chem/physics/math) comparing baseline vs SAVL on accuracy, token cost, and latency","owner":"eval-pipeline","effort":"medium"}],"retrieval_improvements":["Adversarial retrieval per node: query = negation of claim + domain context, forcing the retrieval system to surface contradicting evidence rather than confirming evidence — this catches hallucinated facts that confirmatory retrieval misses","Assumption-targeted retrieval: for each explicit assumption listed in a ClaimDAG node, run a dedicated retrieval pass to verify the assumption holds in the specific domain context (e.g. ideal gas assumption validity range)","Verifier-triggered retrieval: when Verifier detects a numerical anomaly, automatically fetch canonical reference values (physical constants, reaction enthalpies, etc.) from authoritative sources and inject into the re-plan context"],"evaluation_plan":["Primary metric: accuracy on HLE hard STEM subset (target: +6-10 pp over baseline), stratified by domain (math, physics, chemistry, biology) to identify where SAVL helps most","Process metric: track rate at which Critic falsifies intermediate nodes before they reach final answer (high falsification-before-answer rate = SAVL catching errors early as intended)","Cost/latency profiling: measure mean tokens-per-correct-answer and mean wall-clock latency vs baseline, with Pareto frontier analysis to identify optimal iteration cap and parallelism settings"],"risks":["Critic over-aggressiveness: adversarial retrieval may surface superficially contradicting but actually irrelevant evidence, causing false falsifications that force unnecessary re-planning and degrade correct answers — mitigate by requiring Critic to score evidence relevance before issuing falsification verdict","Iteration cap too low: capping at 3 re-plan iterations may be insufficient for deeply nested multi-step problems (e.g. 8-step organic synthesis), leaving errors uncorrected — mitigate by making cap configurable per problem depth estimate from Planner","Latency blowup on parallel Critic fan-out: for ClaimDAGs with many independent nodes, parallel Critic calls may saturate rate limits — mitigate with priority-based fan-out that critiques high-centrality nodes first"]}
```
