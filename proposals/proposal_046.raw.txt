```json
{
  "proposal_id": "SPARKIT-2026-02-22-001",
  "title": "Option-Discriminative Adversarial Retrieval with Disagreement-Gated Solver Upgrade",
  "distinctive_angle": "Shifts SPARKIT retrieval from question-centric intent queries to pairwise MCQ option discrimination and active hypothesis falsification, then uses inter-source claim disagreement as a dynamic routing signal to auto-upgrade contested questions to the research_max dual-solver — eliminating the confirmation bias baked into current intent-query design without adding a blanket cost increase.",
  "summary": "Three tightly coupled improvements: (1) Pairwise Option Contrast Queries generate retrieval terms from the token-set difference and intersection of the two most similar MCQ option pairs, forcing retrieval engines to surface comparative studies and direct experimental comparisons rather than generic supportive evidence for each option in isolation; (2) Active Falsification Sub-Rounds execute a dedicated retrieval pass per surviving MCQ option appending negation/failure vocabulary to option text, treating the option as a falsifiable hypothesis — options unable to find disconfirming evidence score higher at blend time; (3) Source-Disagreement Triangulation clusters retrieved documents by abstract n-gram overlap, detects conflicting first-sentence claims via antonym and negation surface patterns anchored to answer-choice entity terms, and auto-routes disagreement-high questions to research_max debate mode while injecting a targeted meta-analysis reconciliation query into the final retrieval round. A fourth supporting improvement seeds round-2+ query vocabulary with low-frequency domain terms extracted from round-1 retrieved abstracts, improving precision on technical jargon absent from the original question.",
  "reasoning": "SPARKIT's current retrieval plan generates intent queries at the whole-question level (primary, methods, adversarial, reference, options). For hard MCQ, the correct option often differs from distractors by a single subtle mechanistic distinction — pathway specificity, temporal ordering, species dependency, reaction condition — that is invisible to question-level token overlap scoring. Pairwise contrast queries explicitly force retrieval to find documents containing terms from both options in close proximity, which selects for comparative studies and systematic reviews uniquely informative for hard disambiguation. The falsification round addresses a separate failure mode: for hard questions, any plausible MCQ option finds some supporting evidence in the literature. Confirmation-biased retrieval gives all options a roughly equal evidence base, making LLM scoring noisy. The option that cannot find disconfirming evidence is more likely correct — this is hypothesis-testing logic that SPARKIT does not currently exploit. Source disagreement detection addresses calibration overconfidence: when peer-reviewed sources conflict, proceeding with standard synthesis often produces overconfident wrong answers; routing specifically to research_max debate mode on disagreement-flagged evidence sets is precisely the adversarial workflow that mode was designed for. Vocabulary-seeded round-2 queries exploit an information asymmetry: hard STEM questions often use lay terminology while the relevant literature uses domain-specific jargon; round-1 abstracts already contain that jargon and can be mined cheaply to improve round-2 precision without any external API.",
  "expected_impact": {
    "accuracy_delta_pct_points": 5,
    "cost_impact": "increase",
    "latency_impact": "increase",
    "confidence": "medium"
  },
  "implementation_plan": [
    {
      "step": "Add pairwise_contrast intent type to _build_retrieval_plan in engine.py: for each pair of MCQ options sharing >40% token overlap (Jaccard on whitespace-split tokens after stopword removal), generate a query '{shared_tokens} {option_A_unique_tokens} versus {option_B_unique_tokens}'. Append to round_queries with intent='pairwise_contrast'. Cap at 3 pairs per question to bound cost. Guard with SPARKIT_ENABLE_PAIRWISE_CONTRAST=1 env flag, default on in research_max, off in standard.",
      "owner": "services/orchestrator/app/engine.py:_build_retrieval_plan",
      "effort": "medium"
    },
    {
      "step": "Implement option-level falsification sub-round in _build_round_queries: after round 1 completes, for each MCQ option not eliminated in the elimination pass, generate a query '{option_text} fail limitation does not exception negative result' and add as a new 'falsification' intent in the next retrieval round. Track falsification_hit_count per option (count of retrieved passages containing the option's key noun-phrase plus a negation token within 100 characters). Expose falsification_hit_count in the round artifact dict.",
      "owner": "services/orchestrator/app/engine.py:_build_round_queries + retrieval stage",
      "effort": "medium"
    },
    {
      "step": "Wire falsification_hit_count into MCQ blend scoring in _score_mcq_options: subtract 0.15 from blended_net_score for any option where falsification_hit_count >= 2 and the falsifying passages are from sections other than 'introduction' or 'methods' (to avoid penalizing options based on motivation sentences). Add SPARKIT_FALSIFICATION_PENALTY=0.15 env knob.",
      "owner": "services/orchestrator/app/engine.py:_score_mcq_options",
      "effort": "low"
    },
    {
      "step": "Implement source_disagreement_score in evidence aggregation: after record deduplication, for each pair of records where both titles share a question answer-choice entity token, compare their first retrieved sentences for antonym/negation surface patterns from a 20-pair lookup table (inhibit/activate, increase/decrease, promotes/suppresses, etc.). Set source_disagreement_score = count of conflicting pairs found. Expose in evidence_graph artifact.",
      "owner": "services/orchestrator/app/engine.py:_select_and_ingest_evidence",
      "effort": "high"
    },
    {
      "step": "Wire source_disagreement_score into mode routing: if source_disagreement_score >= 1 AND current mode is not already research_max AND remaining_budget_usd >= estimated research_max cost, upgrade synthesis stage to research_max dual-solver debate for this question only. Log upgrade as uncertainty_reason='source_disagreement_detected'. Add SPARKIT_AUTO_UPGRADE_ON_DISAGREEMENT=1 env gate, default enabled in routed mode.",
      "owner": "services/orchestrator/app/routing.py + engine.py synthesis dispatch",
      "effort": "medium"
    },
    {
      "step": "Add vocabulary-expansion seeding for round-2+ queries: after round 1 retrieval completes, collect tokens from all retrieved abstracts, remove stopwords and tokens already present in the original question, count frequency, take the top-5 tokens appearing in 2-4 documents (low-frequency signal of domain jargon, not noise), append to the primary-intent query string for round 2 only. Gate with SPARKIT_VOCAB_SEED_ROUND2=1.",
      "owner": "services/orchestrator/app/engine.py:_build_round_queries",
      "effort": "low"
    },
    {
      "step": "Add a meta-analysis reconciliation query when source_disagreement_score >= 1: inject a final retrieval query '{question_core_terms} systematic review meta-analysis reconcile conflicting' targeting arXiv and Semantic Scholar adapters. This specifically seeks documents that have already synthesized the conflicting primary literature.",
      "owner": "services/retrieval_service/app/aggregator.py + engine.py retrieval plan",
      "effort": "low"
    },
    {
      "step": "Extend test_synthesis_quality.py with unit tests for: pairwise_contrast query generation given option pairs with >40% overlap; no pairwise query when options share <40% overlap; falsification_hit_count computation from passage fixtures; MCQ blend score reduction when falsification_hit_count >= 2; source_disagreement_score = 0 when records have no conflicting first-sentence claims; source_disagreement_score >= 1 when injected conflicting fixture records are present; mode auto-upgrade trigger condition check.",
      "owner": "services/orchestrator/tests/test_synthesis_quality.py",
      "effort": "medium"
    },
    {
      "step": "Create MCQ-hard benchmark split: identify HLE questions where the top-2 MCQ options share >40% token overlap (manually or via offline script). Run 20-question smoke test on this split with features individually toggled (pairwise_contrast only, falsification only, vocab_seed only, all combined) to validate signal direction before committing a full HLE-149 run and its associated cost.",
      "owner": "services/eval_service + benchmarks/",
      "effort": "medium"
    }
  ],
  "retrieval_improvements": [
    "Pairwise option contrast queries: for MCQ option pairs sharing >40% token Jaccard overlap, generate retrieval queries from the shared token intersection plus each option's unique tokens framed as a 'versus' comparison. This targets comparative studies and head-to-head experimental papers that directly distinguish the two candidate answers, a document type that question-level queries systematically miss.",
    "Active falsification sub-round per surviving option: after round-1 retrieval and elimination, generate a dedicated retrieval pass for each non-eliminated MCQ option appending 'fail limitation does not exception negative result' to option text. Tracks falsification_hit_count per option across all six academic adapters, exposing a hypothesis-survival signal that is absent from current SPARKIT retrieval entirely.",
    "Vocabulary-expansion seeding from round-1 abstracts into round-2 queries: extract low-frequency domain tokens (present in 2-4 retrieved abstracts, absent from original question) and inject the top-5 into the round-2 primary-intent query. Bridges the terminology gap between lay-language questions and domain-specific jargon in the literature without requiring any additional external API calls.",
    "Meta-analysis reconciliation query on source disagreement: when conflicting first-sentence claims are detected across retrieved records that share an answer-choice entity term, inject a targeted query for systematic reviews and meta-analyses resolving the specific conflict into the final retrieval round, specifically surfacing documents that have already adjudicated the primary-literature dispute.",
    "Pairwise contrast evidence dossier in option scoring: extend the existing option_dossier construction to include a contrast_snippets field per option pair, comprising passages that mention both options' key noun-phrases within 200 tokens of each other. Provides the synthesis LLM with directly comparative evidence rather than requiring it to mentally compare option-by-option evidence from separate documents, reducing the compositional reasoning burden on synthesis."
  ],
  "evaluation_plan": [
    "Accuracy delta on MCQ-hard split: define MCQ-hard as HLE questions where top-2 MCQ options share >40% token Jaccard overlap. Measure baseline vs proposal accuracy on a 20+ question subset before committing to full HLE-149. Require +3 pp minimum to declare signal positive. If below threshold, inspect falsification query logs to distinguish between falsification false-positives and genuine no-signal cases.",
    "Falsification signal validity: for 30 held-out HLE questions with known correct answers, measure whether correct options have statistically lower falsification_hit_count than incorrect options (one-tailed Mann-Whitney U test, p < 0.10 threshold). If the signal is inverted or null, disable the falsification penalty and log the finding; do not apply a penalty that is not validated.",
    "Pairwise contrast query discriminativeness audit: for 20 hard MCQ questions, manually inspect the top-5 documents retrieved by each pairwise_contrast query and score each as discriminative (mentions both option-A and option-B key terms) or non-discriminative (mentions only one). Require >50% discriminative rate to confirm the query design is working; if below, adjust the query template to strengthen the 'versus' framing.",
    "Source-disagreement routing trigger rate: verify that auto-upgrade to research_max activates on 10-30% of hard questions across a 50-question evaluation run. A trigger rate below 10% indicates the disagreement detector is too conservative; above 30% indicates noise. Instrument as a named observability metric disagreement_upgrade_rate and surface in the per-run trace.",
    "Calibration improvement on disagreement-flagged questions: for questions where source_disagreement_score >= 1, measure ECE and Brier score before and after the auto-upgrade routing. Expect ECE reduction of >0.02 on this subset, reflecting that the debate mode produces better-calibrated confidence on contested questions. Flag if Brier score regresses on non-disagreement questions (routing side-effects).",
    "Cost regression gate: measure total per-question cost increase with all features enabled on a 10-question representative batch. If the mean cost increase exceeds 40% over baseline routed mode, gate pairwise_contrast and falsification behind SPARKIT_ENABLE_OPTION_DISC=1 (off by default in standard and routed modes, on only in research_max), and document the tradeoff in configuration.md."
  ],
  "risks": [
    "Falsification query false positives: academic abstracts frequently contain negation in motivation sentences ('X has not been shown to...') that do not represent disconfirming evidence for a specific MCQ option. Mitigation: require falsification_hit_count >= 2 disconfirming passages AND restrict to passages from 'results' or 'discussion' sections; reject passages in 'introduction' or 'methods' where null results are stated as motivation. Add a section-type guard in the falsification_hit_count computation.",
    "Pairwise contrast query degeneracy for distinct options: when MCQ options are semantically distinct, the shared token intersection is small and pairwise contrast queries collapse to the primary intent query, adding cost without benefit. Mitigation: enforce the >40% token Jaccard overlap threshold strictly and skip pairwise_contrast generation entirely when no pairs meet it; log skip events in the run trace for observability.",
    "Source-disagreement detector false positives from coincidental negation: two papers can both contain 'X does not inhibit Y' for different Y values, appearing to disagree when they do not. Mitigation: restrict disagreement detection to pairs where both records share the same answer-choice entity token and the conflicting predicate applies to the same entity; validate the 20-pair antonym lookup table with manual review of 20 real cases before enabling auto-upgrade routing.",
    "Budget blowout from auto-upgrade to research_max: the dual-solver plus debate judge adds 3-4 extra LLM calls per question. If this triggers on many questions in a batch run, total cost could exceed planned budgets. Mitigation: auto-upgrade only fires if remaining_budget_usd >= 1.5x estimated research_max cost for that question; otherwise log the disagreement signal as an uncertainty_reason without mode change, and add SPARKIT_MAX_AUTO_UPGRADES_PER_BATCH=N config knob.",
    "Vocabulary seeding introducing domain drift: low-frequency tokens from round-1 abstracts may include author names, institution names, or highly specific experimental conditions that narrow retrieval too aggressively in round-2, reducing recall. Mitigation: filter seeded tokens to only those matching a POS heuristic for nouns and adjectives (no all-caps tokens, no tokens containing digits, length 5-20 chars), and limit to tokens appearing in at least 2 of the round-1 retrieved abstracts to reduce noise from single-document idiosyncrasies."
  ]
}
```
