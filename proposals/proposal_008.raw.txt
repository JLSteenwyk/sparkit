```json
{
  "proposal_id": "SPARKIT-P-2026-MCR-001",
  "title": "Mechanistic Chain-of-Retrieval with Cross-Document Passage Entailment Scoring",
  "distinctive_angle": "Instead of treating hard questions as keyword lookup problems, generate a short mechanistic reasoning chain per MCQ option BEFORE retrieval, retrieve evidence for each chain step independently, then score cross-document entailment to build a consistency graph that reweights the synthesis evidence pack — making retrieval driven by implicit causal structure rather than surface token overlap.",
  "summary": "SPARKIT currently decomposes questions into keyword-typed query sets and scores retrieved passages by lexical overlap. For hard STEM questions (HLE chemistry/biology tier), correct answers often depend on multi-step mechanistic reasoning that is never explicitly stated in any single paper. This proposal adds three interlocking layers: (1) Mechanism Chain Generation — the LLM produces a 3–5 step causal/mechanistic chain for EACH MCQ option before any retrieval begins, seeding option-specific retrieval with mechanistic sub-queries rather than just option text; (2) Passage Entailment Scoring — after ingestion, pairs of passages are scored for mutual entailment vs contradiction using a lightweight LLM call, building a directed consistency graph used to upweight high-consensus clusters and downweight isolated claims; (3) Chain Closure Verification — a dedicated post-retrieval LLM pass checks how many steps in each option's mechanism chain are 'closed' by retrieved evidence, producing a per-option chain-coverage score that replaces the current lexical blend weight in MCQ scoring.",
  "reasoning": "Three root causes explain SPARKIT underperformance on HLE-tier hard questions. First, the retrieval planner generates queries from question surface tokens, but hard chemistry and biology questions require mechanistic sub-concepts that never appear verbatim in the question stem (e.g., a question about stereoselectivity requires retrieving evidence about the underlying orbital geometry or transition state — concepts not mentioned in the question). Mechanism chains pre-materialize these latent sub-concepts before retrieval begins, dramatically increasing recall for relevant mechanistic evidence. Second, the current evidence synthesis pack is built from claim text that is at most 180 characters (title + first sentence of best section), giving the synthesizer almost no passage content to reason over; this is the codebase's single biggest grounding gap (see engine.py _select_best_section_chunk and the claim construction in execute_orchestration). Third, the MCQ blended score currently mixes a 0.7-weight LLM score with a 0.3-weight lexical overlap score — the lexical component is noise for hard questions where the correct answer is not the most lexically similar to retrieved text. Replacing lexical weight with chain-closure coverage (how many mechanistic steps have evidence) gives the blended score a genuine epistemic signal rather than a superficial token-count proxy.",
  "expected_impact": {
    "accuracy_delta_pct_points": 8,
    "cost_impact": "increase",
    "latency_impact": "increase",
    "confidence": "medium"
  },
  "implementation_plan": [
    {
      "step": "Add _generate_mechanism_chains() to engine.py: given question stem + MCQ options, call synthesis_provider with a structured prompt requesting a JSON blob of {option_letter: [{step_index, mechanism_description, key_entities, retrieval_seed_query}]} for each option. Cap at 4 steps per option. Cache result on the orchestration context object to avoid re-calling on retries. Insert call at the start of execute_orchestration() after _decompose_retrieval(), merging the retrieval_seed_query values into the plan's queries_methods list for the retrieval_round_option_hypotheses round. This touches only engine.py and requires no schema changes.",
      "owner": "orchestrator",
      "effort": "medium"
    },
    {
      "step": "Extend _build_round_queries_from_plan() in engine.py to emit mechanism-step queries as a new intent type 'retrieval_round_mechanism_chains'. These queries are shorter (one per step per option) and should be dispatched with higher per-query result targets (e.g., max_results=6 instead of 3) because mechanism step concepts are narrow and relevant papers may be sparse. This is purely additive — new elif branch in the round builder — and does not break existing retrieval logic.",
      "owner": "orchestrator",
      "effort": "low"
    },
    {
      "step": "Add _score_passage_entailment_pairs() to verifier.py: after all ingestion is complete, sample up to 20 ingested passage chunks (those with >100 tokens) and call the synthesis_provider with a batched entailment prompt that returns a JSON matrix of pairwise relations: 'entails', 'neutral', or 'contradicts'. Build a consistency score per passage: consistency = (entailment_count - contradiction_count) / max(1, comparison_count). Attach consistency_score to each ingested record. This call should be skipped if budget < $1.50 or if ingested docs < 5.",
      "owner": "orchestrator + verifier",
      "effort": "high"
    },
    {
      "step": "Modify _build_option_dossiers() in engine.py to incorporate passage consistency_score: when selecting support_snippets for an option dossier, multiply the existing snippet score by (1 + 0.4 * consistency_score) and multiply counter_snippet scores by (1 - 0.3 * consistency_score). This ensures that high-consensus passages are preferentially used as support evidence and that isolated contradictory passages have lower counter weight. The change is localized to the dossier builder and does not alter downstream calling code.",
      "owner": "orchestrator",
      "effort": "low"
    },
    {
      "step": "Add _compute_chain_closure_score() to engine.py: given a mechanism chain (list of step dicts) and the full set of ingested records, for each step compute: step_closed = max(token_overlap(step.key_entities, record.best_section_text)) >= 0.25 across all records. chain_closure_score = closed_steps / total_steps. Replace the current 0.30 * lexical_score weight in _blend_mcq_scores() with 0.30 * chain_closure_score. If mechanism chains were not generated (budget too low or non-MCQ), fall back to existing lexical weight.",
      "owner": "orchestrator",
      "effort": "medium"
    },
    {
      "step": "Add budget guard: _generate_mechanism_chains() and _score_passage_entailment_pairs() should be gated by a new env var SPARKIT_ENABLE_MECHANISM_CHAINS (default 1) and only run when max_cost_usd >= 2.0. Below this threshold, fall back to the current pipeline. Add cost estimates (mechanism chain call ~$0.003, entailment matrix call ~$0.015 for 20 passages) to policy.py's cost estimator so they are deducted from budget.",
      "owner": "orchestrator + policy",
      "effort": "low"
    },
    {
      "step": "Add tests to test_synthesis_quality.py: (a) mock _generate_mechanism_chains output and verify chain steps appear in round queries; (b) test _compute_chain_closure_score returns 1.0 when all steps have matching passages, 0.0 when none do; (c) test _score_passage_entailment_pairs builds consistent score correctly from mock LLM response; (d) test that dossier builder scores shift correctly when consistency_score is injected.",
      "owner": "eval",
      "effort": "medium"
    },
    {
      "step": "Run controlled A/B on HLE-25 balanced benchmark: baseline (current HEAD) vs mechanism-chains enabled, same budget cap $4.00, same provider. Log per-question: chain_closure_scores for each option, whether the selected option matched the highest closure score, and whether closure score agreed with judge output. Use this to tune the 0.30 weight and the 0.25 closure threshold.",
      "owner": "eval",
      "effort": "medium"
    }
  ],
  "retrieval_improvements": [
    "Mechanism-step sub-queries: each MCQ option's 3–5 mechanistic steps generate narrow, concept-specific retrieval seeds (e.g., for a Diels-Alder question, step 2 might seed 'endo rule transition state orbital symmetry' rather than the option text 'product C'). This addresses the core gap where hard questions require latent mechanistic knowledge never stated in the question stem. Expected to increase recall of directly relevant mechanistic papers by 15–25% on chemistry HLE questions.",
    "Entailment-reweighted dossier construction: passage consistency_score (from pairwise entailment scoring) is used to upweight cross-corroborated evidence in option dossiers. Currently the dossier treats all support snippets equally regardless of whether other papers agree; this change ensures that a snippet corroborated by 5 other passages outweighs an isolated claim — directly improving precision of the evidence pack fed to the MCQ scorer and judge.",
    "Targeted ingestion expansion for mechanism steps: the new retrieval_round_mechanism_chains round fetches documents specifically for each mechanistic sub-step, not just for the option letter or stem keywords. Because mechanism step queries are narrower and more semantically specific than option-text queries, the ingested passages are more likely to contain the precise technical detail needed. In SPARKIT's ingestion path (parser.py fetch_and_parse + _select_best_section_chunk), narrower queries also improve the quality of the best_section_chunk selection because the focus_terms set is enriched with key_entities from the mechanism steps.",
    "Chain-closure replaces lexical blend weight: the current 0.30 * lexical_overlap weight in _blend_mcq_scores() is computed from token overlap between option text and retrieved titles/abstracts — a noisy proxy that can favor options whose keywords happen to co-occur with retrieved papers regardless of meaning. Chain-closure score is a direct epistemic signal: 'how many of the mechanistic steps required for this option to be correct are actually backed by retrieved evidence?' This is semantically grounded rather than superficially lexical.",
    "Evidence consistency graph for synthesis: the pairwise entailment matrix enables the synthesizer to receive an ordered evidence pack where the most cross-corroborated passages appear first. Currently, evidence packaging in engine.py _build_synthesis_prompt orders by source and section type — independent of internal consistency. Reordering by consistency_score ensures the LLM synthesizer sees the strongest epistemic cluster first, reducing hallucination of support for inconsistent claims."
  ],
  "evaluation_plan": [
    "Chain coverage vs accuracy correlation: for all HLE-25 runs with mechanism chains enabled, compute Spearman correlation between chain_closure_score of the selected option and binary correctness. If the proposal is working, selected options with closure >= 0.6 should be correct significantly more often than those with closure < 0.3. Target: correlation > 0.3 at p < 0.05 on HLE-25.",
    "Recall@10 for mechanism-step queries vs baseline queries: on a 20-question held-out chemistry sub-sample, manually evaluate the top-10 retrieved papers for each mechanism-step query vs the corresponding options query from the baseline. Count how many of the top-10 are 'directly relevant to the mechanistic reasoning step' (rated by human or GPT-4 judge). Target: mechanism-step queries achieve >= 1.5x the manually-judged recall@10 of options queries for the same question.",
    "Entailment matrix calibration: for 10 question runs, inspect the pairwise entailment output. Check that pairs of passages from the same paper are rated 'entails' or 'neutral' at >= 85% rate (should not contradict themselves). Check that passages citing contradictory experimental results (e.g., two papers reporting opposite stereochemical outcomes) are rated 'contradicts' at >= 60% rate on a manually curated mini-set of known contradictory paper pairs. This validates that the entailment call is meaningful and not always returning 'neutral'.",
    "MCQ score attribution analysis: for each question, log (a) chain_closure_score per option, (b) LLM_net_score per option, (c) blended score per option, (d) final selected option. Compute how often the highest-closure option matches the highest-LLM-score option vs disagrees. When they disagree, track correctness separately for each signal. If chain_closure is more accurate when disagreeing with LLM score, the 0.30 weight should be raised; if not, it should be lowered or the feature dropped.",
    "A/B accuracy on HLE-25 balanced subset: run both baseline (current HEAD at dce7d9e) and mechanism-chain-enabled build on the same 25 questions with identical budget ($4.00), provider config, and random seed. Primary metric: fraction correct. Secondary metrics: mean confidence, Brier score, ECE. Target: >= 2 additional correct answers (8 percentage points on 25 questions) with Brier score not worsening.",
    "Latency and cost regression gate: assert that the mechanism chain generation call adds <= $0.10 to per-question cost at the $4 budget tier and that total wall-clock latency increase is <= 25% vs baseline. If either threshold is violated, the entailment matrix call (the most expensive new component) should be disabled first."
  ],
  "risks": [
    "Mechanism chain hallucination: the LLM may generate plausible-sounding but factually incorrect mechanistic steps, seeding retrieval with queries for non-existent mechanisms and returning irrelevant papers. Mitigation: constrain mechanism chain prompt to request only steps that are 'well-established in textbooks or primary literature' and add a post-generation filter that drops steps with zero retrieved evidence across all sources (chain step with no evidence likely hallucinated).",
    "Entailment matrix cost at scale: at 20 passage pairs, the pairwise entailment call is O(n^2) = 190 comparisons; at 30 passages this grows to 435. At HLE-25 benchmark scale (25 questions × $0.015 each), total added cost is ~$0.375 — acceptable. But if SPARKIT runs on the full 149-question HLE-gold dataset, the cost is ~$2.24 just for entailment calls. Mitigation: cap the entailment sample at 20 passages regardless of ingestion volume, use clustering (group by DOI prefix) to reduce redundant comparisons, and gate on budget >= $2.",
    "Chain closure threshold sensitivity: the 0.25 token overlap threshold for considering a mechanism step 'closed' is a hyperparameter that may need tuning per domain. Chemistry steps (involving specific molecular names) may have very low overlap with retrieved abstracts even when the paper is directly relevant, causing under-closure. Biology steps (using common gene/protein names) may over-close. Mitigation: start with 0.25, tune separately for chemistry vs biology questions using the domain tag in the HLE benchmark, and expose as SPARKIT_MECHANISM_CLOSURE_THRESHOLD env var.",
    "Increased latency for time-sensitive use cases: adding mechanism chain generation (1 LLM call) + entailment scoring (1 LLM call) + mechanism-step retrieval round adds approximately 8–15 seconds of wall-clock latency on top of current research_max timing. For latency-constrained deployments (max_latency_s < 120), both new LLM calls will be skipped by the budget guard. This means the improvement only materializes at higher budget/latency tiers where users already expect longer waits.",
    "Provider dependency for mechanism chain quality: the quality of mechanism chains depends heavily on the synthesis provider's STEM domain knowledge. Cheaper providers (kimi-k2, mistral) may produce lower-quality chains that seed retrieval poorly. Mitigation: always use the highest-tier configured provider (anthropic > openai > gemini > others, in that order) for mechanism chain generation regardless of routing mode, and log the generating provider in the trace for post-hoc analysis.",
    "Entailment model bias: the LLM used for passage entailment scoring may have systematic biases — e.g., rating abstractly phrased passages as 'neutral' even when they contradict more specific ones, or over-detecting contradiction in papers that merely use different terminology. If entailment scoring is noisy, consistency_score becomes noise and degrades dossier quality. Mitigation: run a calibration check (evaluation plan step 3) before enabling in production; add a kill-switch env var SPARKIT_ENABLE_ENTAILMENT_SCORING separate from SPARKIT_ENABLE_MECHANISM_CHAINS."
  ]
}
```
