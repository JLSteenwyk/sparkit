```json
{
  "proposal_id": "sparkit-rtra-001",
  "title": "Reasoning-Trace-Guided Targeted Retrieval (RTRA)",
  "distinctive_angle": "Invert the retrieve-then-reason pipeline: run a cheap reasoning model before any retrieval, parse its chain-of-thought trace for specific factual assertions and hedged sub-claims, convert those into precision retrieval queries, then anchor synthesis by tagging each final claim as trace-confirmed, trace-contradicted, or trace-unverified — turning the model's own uncertainty into a retrieval roadmap rather than treating uncertainty as a post-hoc calibration penalty.",
  "summary": "RTRA inserts a pre-retrieval pass using DeepSeek-Reasoner (lowest-cost reasoning model already in SPARKIT's client pool at $0.28/M input). The reasoning trace is parsed for three signal types: (1) hedged factual assertions ('I believe', 'approximately', 'if I recall correctly'), (2) explicit self-corrections ('wait, actually'), and (3) numerical values stated without attribution. Each signal type maps to a different retrieval intent: hedged assertions become confirm-or-refute queries, self-corrections become disambiguation queries, and bare numerics become anchor queries combining the value with surrounding context terms. These queries are injected as a new 'trace_targeted' intent into the existing RetrievalPlan.intent_queries dict in _decompose_retrieval(), so they flow through the existing aggregator, deduplication, and ranking pipeline without changes to retrieval_service/. During synthesis, a lightweight claim-trace alignment step tags each extracted claim, shifting CalibrationFeatures confidence scoring toward trace-confirmed evidence.",
  "reasoning": "Hard HLE-style questions fail in SPARKIT because generic keyword queries (derived from question stem + lexical anchors) retrieve papers that are topically adjacent but do not contain the specific intermediate fact needed. The reasoning model's chain-of-thought trace reveals precisely which sub-claims the model depends on but is uncertain about — these are the retrieval gaps. For example, if the trace says 'I think the FWHM of a Lorentzian is 2*gamma but I am not certain about the normalization convention', the correct retrieval query is 'Lorentzian linewidth FWHM normalization gamma convention', not the generic question stem. This is architecturally distinct from every item in the current backlog: the P0 reasoning-mode item wires reasoning for final synthesis; the P1 multi-query decomposition planner decomposes by method/domain/contradiction categories; the P1 draft-critic-revise loop iterates synthesis post-retrieval. RTRA does none of these — it uses reasoning output as a pre-retrieval planner. The trace-derived queries are also far more discriminating than SPARKIT's current adversarial round (which targets broad contradiction markers) because they target specific named sub-claims. DeepSeek-Reasoner is ideal here: its traces are scientifically dense, long, and expose fine-grained uncertainty in ways that non-reasoning models do not. The DeepSeekClient in clients.py already handles the reasoning_content fallback, so the infrastructure exists.",
  "expected_impact": {
    "accuracy_delta_pct_points": 8,
    "cost_impact": "increase",
    "latency_impact": "increase",
    "confidence": "medium"
  },
  "implementation_plan": [
    {
      "step": "Add _generate_reasoning_trace(question: str, options: list[str] | None, client: BaseProviderClient, max_tokens: int = 1500) -> str in engine.py. Call DeepSeekClient (or the configured RTRA_TRACE_MODEL) with a prompt instructing it to reason step-by-step but not produce a final answer. Return the <thinking> block content if present (clients.py already handles reasoning_content fallback for DeepSeek), else return the full response text. Cap at 1500 tokens via max_tokens to bound latency.",
      "owner": "services/orchestrator/app/engine.py",
      "effort": "low"
    },
    {
      "step": "Add _extract_trace_queries(trace_text: str, question: str, max_queries: int = 8) -> list[str] in engine.py. Use three extraction passes: (a) sentence-level hedging detection with regex matching 'I (believe|think|recall|assume)', 'approximately', 'roughly', 'typically', 'if I remember' — extract the containing clause and prepend the dominant domain term from the original question; (b) self-correction detection with regex 'wait,?\\s+actually|let me reconsider|I was wrong' — extract both the original and revised claim as separate queries; (c) bare numeric extraction — find numbers preceded by chemical/physics unit patterns (eV, nm, Hz, K, mol, etc.) and form queries combining the value with its surrounding noun phrase. Deduplicate using trigram Jaccard against existing primary queries (threshold 0.6) before returning.",
      "owner": "services/orchestrator/app/engine.py",
      "effort": "medium"
    },
    {
      "step": "Extend _decompose_retrieval() in engine.py to accept an optional trace_queries: list[str] parameter. When provided and non-empty, add them under the key 'trace_targeted' in the returned RetrievalPlan.intent_queries dict. Update the retrieval loop to treat 'trace_targeted' queries with the same per-query aggregator calls as 'primary' but with a dedicated source budget (max 4 results per query, max 12 total trace_targeted results across all queries). This keeps trace retrieval additive and budget-capped without modifying aggregator.py.",
      "owner": "services/orchestrator/app/engine.py",
      "effort": "low"
    },
    {
      "step": "Run _generate_reasoning_trace() and primary Round 1 retrieval in parallel using asyncio.gather() at the top of the research loop in engine.py. The trace is available before Round 2 begins, so _extract_trace_queries() output is injected into Round 2's retrieval plan as 'trace_targeted' intent. This eliminates added wall-clock latency by overlapping the trace generation with existing retrieval I/O.",
      "owner": "services/orchestrator/app/engine.py",
      "effort": "medium"
    },
    {
      "step": "Add claim-trace alignment in _synthesize_answer(): after claim extraction and before the synthesis prompt is built, compare each claim's text against the list of hedged trace assertions using token overlap (reuse the existing _token_overlap() helper). Tag claims with trace_status in {trace_confirmed, trace_contradicted, trace_unverified}. Inject trace_status annotations into the synthesis prompt context as an additional evidence tier: 'The following claims are corroborated by pre-retrieval reasoning: [...]'. This improves synthesis grounding without changing the prompt structure for untagged claims.",
      "owner": "services/orchestrator/app/engine.py",
      "effort": "medium"
    },
    {
      "step": "Add trace_confirmed_ratio (float, 0-1) and trace_contradiction_rate (float, 0-1) to CalibrationFeatures in services/orchestrator/app/calibration.py and features_to_dict(). Update calibrate_answer() to weight trace_confirmed_ratio as +0.05 bonus to answer_confidence and trace_contradiction_rate as -0.08 penalty, capped at the existing penalty ceiling. Add a corresponding Alembic migration adding these two columns to run_calibration_features.",
      "owner": "services/orchestrator/app/calibration.py + alembic/versions/",
      "effort": "medium"
    },
    {
      "step": "Add SPARKIT_ENABLE_RTRA env var (default false) and RTRA_TRACE_MODEL (default 'deepseek:deepseek-reasoner') and RTRA_COST_RESERVE (default 0.10) to policy.py constants. Gate the pre-retrieval trace pass in engine.py behind this flag AND behind a should_stop_early() budget check ensuring remaining budget > RTRA_COST_RESERVE before calling the trace model. Add RTRA trace cost to BudgetState.cost_usd after the call using the existing estimate_generation_cost() helper.",
      "owner": "services/orchestrator/app/policy.py + engine.py",
      "effort": "low"
    },
    {
      "step": "Add unit tests in services/orchestrator/tests/test_synthesis_quality.py: (1) test _extract_trace_queries returns >= 2 queries from a synthetic trace containing two hedged phrases and one bare numeric; (2) test trace-derived queries are deduplicated against primary queries above the Jaccard threshold; (3) test claim-trace alignment correctly assigns trace_confirmed to a claim whose text substantially overlaps a trace assertion and trace_unverified to a disjoint claim; (4) test CalibrationFeatures accepts trace_confirmed_ratio and trace_contradiction_rate without validation errors. Add a smoke integration test running RTRA on 5 HLE-gold questions with SPARKIT_ENABLE_RTRA=true and asserting trace_confirmed_ratio is present in the calibration output.",
      "owner": "services/orchestrator/tests/test_synthesis_quality.py",
      "effort": "medium"
    }
  ],
  "retrieval_improvements": [
    "Trace-extracted hedged factual assertions become precision retrieval queries targeting the exact sub-claims that the reasoning chain depends on but is uncertain about. These queries name specific concepts, values, or relationships that generic question-stem expansion never produces. For a question about superconductor critical temperatures, if the trace says 'I think niobium has a Tc of around 9.2 K', the trace query is 'niobium superconductor critical temperature Tc 9.2 K measurement', which surfaces the exact measurement paper rather than generic superconductivity reviews.",
    "Self-correction events in the trace (detected by 'wait, actually' and 'let me reconsider' patterns) indicate that the model's parametric knowledge is internally inconsistent on a specific sub-claim. Both the original and revised versions of the claim become retrieval queries, creating a mini-adversarial pair specifically targeted at the point of model confusion. This is more precise than SPARKIT's current adversarial retrieval round, which searches for contradictions across the entire topic area using broad marker keywords.",
    "Bare numeric values extracted from the trace (physical constants, reaction yields, spectral values, dates) are combined with their surrounding noun phrase and unit to form hybrid text-numeric queries. These are highly discriminating because only papers reporting or deriving that specific value will match, eliminating the topical-but-irrelevant papers that dominate keyword-only retrieval. The existing adapters (arXiv abstract search, Semantic Scholar, Crossref) all support full-phrase queries that will respond well to this specificity.",
    "Trace-targeted queries are injected as a dedicated 'trace_targeted' intent in RetrievalPlan.intent_queries and participate in the existing aggregator deduplication, source-diversity capping, and token-overlap ranking without any changes to retrieval_service/. This means trace-derived queries compete fairly against primary queries: only passages genuinely relevant to both the question and the trace sub-claim survive into the synthesis context, preventing trace queries from flooding the evidence pool with tangential material.",
    "Parallel execution of trace generation and Round 1 primary retrieval (via asyncio.gather()) means the trace-targeted intent is available for injection into Round 2 without adding wall-clock latency. The existing adaptive retrieval gating logic (SPARKIT_ADAPTIVE_MIN_QUALITY_GAIN) will then measure whether the trace-targeted round produces sufficient new relevance gain, ensuring the extra retrieval effort is spent only when the trace indicates genuine uncertainty."
  ],
  "evaluation_plan": [
    "Run SPARKIT in RTRA-on vs. RTRA-off conditions on the full HLE-gold benchmark (149 questions) with all other settings held constant (same provider, same mode, same budget). Compare accuracy, trace_confirmed_ratio mean, cost per run, and total latency. Target threshold: >= 5 percentage point accuracy improvement with cost increase < $0.05 per run average and p95 latency increase < 20s.",
    "Compute Pearson correlation between trace_confirmed_ratio and is_correct across HLE-gold RTRA runs. If RTRA retrieval is functioning correctly, questions where trace_confirmed_ratio > 0.6 should have substantially higher accuracy than questions where trace_confirmed_ratio < 0.2. A correlation coefficient < 0.15 indicates the trace alignment tagging is not predictive and the alignment logic needs revision.",
    "Manually audit 20 randomly sampled RTRA runs: for each, count the number of trace-targeted queries that retrieved at least one document with a DOI not seen in primary or adversarial rounds. Target: >= 60% of RTRA runs should introduce at least one novel document via trace-targeted queries. If fewer, the deduplication Jaccard threshold (0.6) is too aggressive and should be lowered.",
    "Verify that hedging-phrase frequency in traces correlates with question difficulty: compute the mean number of hedged assertions detected per question for the hardest quartile of HLE questions (by direct-call accuracy) vs. the easiest quartile. The hard quartile should produce >= 2x more hedging phrases on average. This validates the core assumption that trace uncertainty is a reliable proxy for retrieval gaps.",
    "Regression test: run RTRA on the full STEM-Exam-200 benchmark and confirm accuracy does not regress more than 2 percentage points versus the non-RTRA baseline. RTRA should be additive on hard questions without harming easier ones where primary retrieval already succeeds.",
    "Latency profiling: measure _generate_reasoning_trace() wall time on 50 HLE questions using DeepSeek-Reasoner at the default 1500-token cap. Compute p50 and p95. If p95 > 15s, reduce RTRA_MAX_TRACE_TOKENS to 1000 and re-measure. Confirm that asyncio.gather() parallelism with Round 1 retrieval results in < 5s net added latency at p50 compared to the sequential baseline."
  ],
  "risks": [
    "Confirmation bias: if the reasoning model's trace contains confidently wrong factual assertions, RTRA will retrieve evidence specifically about those wrong sub-claims, potentially surfacing distractor papers that reinforce the incorrect reasoning path. Mitigation: the trace_contradiction_rate penalty in CalibrationFeatures will reduce answer confidence when retrieved evidence refutes trace assertions rather than supporting them, and the synthesis prompt instructs the model to treat trace_contradicted evidence as an override signal over the trace's original claim.",
    "Trace parsing fragility: different reasoning models produce traces in different formats (DeepSeek uses thinking blocks, Grok uses inline reasoning, some models produce flat prose with no structural markers). The hedging regex may miss domain-specific uncertainty language ('the literature suggests', 'it has been reported') that does not use first-person hedges. Mitigation: implement a secondary LLM-based extraction fallback for RTRA_TRACE_MODEL values that are not DeepSeek: a single cheap prompt asking the model to list its top 3 uncertain sub-claims from a provided reasoning paragraph.",
    "Redundant query overlap with existing intents: some trace-derived queries may overlap substantially with primary or options queries already planned by _decompose_retrieval(), adding API cost without new retrieval signal. Mitigation: the Jaccard deduplication pass in _extract_trace_queries() (threshold 0.6 against all existing intent queries) prevents the most direct overlaps, and the per-query result cap (max 4 results per trace query) limits cost even if the deduplication misses some.",
    "Budget exhaustion on tight-budget runs: RTRA adds one reasoning model call plus up to 8 additional retrieval queries, which on budget-constrained runs (max_cost_usd < $0.25) may exhaust the budget before synthesis. Mitigation: the RTRA_COST_RESERVE gate in policy.py (default $0.10) prevents RTRA from activating when budget is insufficient, and SPARKIT_ENABLE_RTRA=false is the default so existing runs are unaffected.",
    "Trace verbosity for mathematical questions: DeepSeek-Reasoner traces for problems involving symbolic derivation can reach 3000-5000 tokens of step-by-step algebra, producing dozens of candidate extraction targets and overwhelming the max_queries=8 cap with low-signal intermediate steps. Mitigation: add a post-extraction relevance filter that scores each candidate query against the original question using _token_overlap() and discards queries with overlap < 0.15, ensuring only traces with genuine connection to the question topic generate retrieval queries."
  ]
}
```
